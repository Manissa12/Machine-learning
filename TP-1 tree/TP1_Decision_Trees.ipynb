{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Decision Trees for Loan Approval\n",
                "\n",
                "**Dataset**: Loan Approval Classification Data (Kaggle)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 1 â€“ Understanding the Problem & Dataset\n",
                "\n",
                "### Business Question\n",
                "Banks want to decide whether to approve or reject a loan application.\n",
                "- **Approve \"1\"**: the applicant is trustworthy enough.\n",
                "- **Reject \"0\"**: too risky for the bank.\n",
                "\n",
                "We will try to predict loan approval (binary classification) using features like:\n",
                "- Age of the applicant\n",
                "- Gender\n",
                "- Credit score\n",
                "- Loan intent (education, personal, home improvement, â€¦)\n",
                "- Income and loan amount\n",
                "- Previous defaults\n",
                "- Others check on kaggle\n",
                "\n",
                "This is a business decision problem: approving risky loans costs the bank money, rejecting too many loans loses potential customers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 1 â€“ Load the dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Load dataset\n",
                "df = pd.read_csv(\"loan_data.csv\")\n",
                "\n",
                "# First look at the dataset\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2 â€“ Dataset structure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3 â€“ Target distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "sns.countplot(x=\"loan_status\", data=df)\n",
                "plt.title(\"Loan Status Distribution (0=Rejected, 1=Approved)\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4 â€“ Gender distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gender_counts = df['person_gender'].value_counts()\n",
                "plt.figure(figsize=(6,6))\n",
                "plt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', \n",
                "        startangle=140, colors=['#66b3ff','#ff9999'])\n",
                "plt.title(\"Distribution of Genders\")\n",
                "plt.axis(\"equal\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 5 â€“ Credit score distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.histplot(df['credit_score'], bins=30, kde=True)\n",
                "plt.title(\"Distribution of Credit Scores\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ”Ž Step 6 â€“ Loan amount vs approval"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10,6))\n",
                "sns.kdeplot(data=df[df['loan_status']==1], x='loan_amnt', label='Approved',\n",
                "            fill=True, color='green')\n",
                "sns.kdeplot(data=df[df['loan_status']==0], x='loan_amnt', label='Declined',\n",
                "            fill=True, color='red')\n",
                "plt.title(\"Loan Amount Distribution by Loan Status\")\n",
                "plt.xlabel(\"Loan Amount\")\n",
                "plt.ylabel(\"Density\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 7 â€“ Correlation analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "le = LabelEncoder()\n",
                "df1 = df.copy()\n",
                "df1['person_gender'] = le.fit_transform(df1['person_gender'])\n",
                "df1['previous_loan_defaults_on_file'] = le.fit_transform(df1['previous_loan_defaults_on_file'])\n",
                "df1 = pd.get_dummies(df1, columns=['person_education', 'person_home_ownership', 'loan_intent'], drop_first=True, dtype=int)\n",
                "correlation_matrix = df1.corr()\n",
                "\n",
                "plt.figure(figsize=(12,10))\n",
                "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
                "plt.title(\"Correlation Heatmap\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 2 â€“ Building a Decision Tree Classifier"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 1 â€“ Splitting the dataset\n",
                "\n",
                "We don't want to test our model on the same data we train it on â†’ risk of overfitting.\n",
                "\n",
                "So we split into Train, Validation, Test sets:\n",
                "- **Train (60%)** â†’ learn model parameters\n",
                "- **Validation (20%)** â†’ tune hyperparameters (max depth, criterion, â€¦)\n",
                "- **Test (20%)** â†’ final evaluation, untouched until the end"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "import numpy as np\n",
                "\n",
                "def make_data(df, cols=None, verbos=False):\n",
                "    # Features & Target\n",
                "    X = df.drop(columns=[\"loan_status\"])\n",
                "    if cols:\n",
                "        X = X[cols]\n",
                "    y = df[\"loan_status\"]\n",
                "\n",
                "    # Splits\n",
                "    TEST_SIZE = 0.2\n",
                "    VAL_SIZE = 0.2\n",
                "    RANDOM_STATE = 42\n",
                "\n",
                "    # First split off test\n",
                "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
                "        X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
                "    )\n",
                "\n",
                "    # Then split temp into train/val\n",
                "    val_size_adjusted = VAL_SIZE / (1 - TEST_SIZE)\n",
                "    X_train, X_val, y_train, y_val = train_test_split(\n",
                "        X_temp, y_temp, test_size=val_size_adjusted, stratify=y_temp, random_state=RANDOM_STATE\n",
                "    )\n",
                "\n",
                "    if verbos:\n",
                "        print(\n",
                "            f\"Train: {len(X_train)} ({(1-TEST_SIZE-VAL_SIZE):.0%}) | \"\n",
                "            f\"Val: {len(X_val)} ({VAL_SIZE:.0%}) | \"\n",
                "            f\"Test: {len(X_test)} ({TEST_SIZE:.0%})\"\n",
                "        )\n",
                "\n",
                "    # Identify column types\n",
                "    cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
                "    num_cols = X.select_dtypes(include=[np.number, \"float64\", \"int64\"]).columns.tolist()\n",
                "\n",
                "    # Preprocessor: OneHot for categorical, passthrough for numeric\n",
                "    preprocess = ColumnTransformer(\n",
                "        transformers=[\n",
                "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
                "            (\"num\", \"passthrough\", num_cols),\n",
                "        ]\n",
                "    )\n",
                "    return X_train, X_val, X_test, y_train, y_val, y_test, cat_cols, num_cols, preprocess"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2 â€“ Training a Decision Tree\n",
                "\n",
                "We'll start with a shallow tree (max_depth=3) for interpretability, just like in the Iris demo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "def model_tree(preprocess, X_train, X_val, y_train, y_val, max_depth=3, criterion=\"gini\", val=True):\n",
                "    tree_clf = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion, random_state=42)\n",
                "    model = Pipeline(steps=[(\"prep\", preprocess), (\"tree\", tree_clf)])\n",
                "    model.fit(X_train, y_train)\n",
                "\n",
                "    if val:\n",
                "        y_pred = model.predict(X_val)\n",
                "        print(classification_report(y_val, y_pred, digits=3))\n",
                "    return model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3 â€“ Train and Evaluate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare splits\n",
                "X_train, X_val, X_test, y_train, y_val, y_test, cat_cols, num_cols, preprocess = make_data(df, verbos=True)\n",
                "\n",
                "# Train a simple tree\n",
                "model = model_tree(preprocess, X_train, X_val, y_train, y_val, max_depth=5, val=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4 â€“ Visualizing the Tree\n",
                "\n",
                "We export to Graphviz to see the rules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.tree import export_graphviz\n",
                "from graphviz import Source\n",
                "import os\n",
                "\n",
                "# Recover one-hot encoded feature names\n",
                "ohe = model.named_steps[\"prep\"].named_transformers_[\"cat\"]\n",
                "ohe_names = ohe.get_feature_names_out(cat_cols)\n",
                "feature_names = np.r_[ohe_names, num_cols]\n",
                "\n",
                "# Export tree\n",
                "path_file = \"DT/images/loan_tree.dot\"\n",
                "export_graphviz(\n",
                "    model.named_steps[\"tree\"],\n",
                "    out_file=path_file,\n",
                "    feature_names=feature_names,\n",
                "    class_names=[\"Rejected\", \"Approved\"],\n",
                "    rounded=True,\n",
                "    filled=True,\n",
                "    proportion=True,\n",
                "    impurity=True\n",
                ")\n",
                "Source.from_file(path_file)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 3 â€“ Interpreting the Decision Tree\n",
                "\n",
                "Now that we have trained a Decision Tree, let's understand what it learned:\n",
                "- Which features are most important?\n",
                "- How do we visualize the decision boundaries in 2D?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 1 â€“ Feature Importance\n",
                "\n",
                "Decision Trees assign an importance score to each feature based on how much it reduces impurity (Gini/Entropy)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract feature names after preprocessing\n",
                "feature_names = [i[5:] for i in model.named_steps['prep'].get_feature_names_out()]\n",
                "\n",
                "# Get feature importances from classifier\n",
                "importances = model.named_steps['tree'].feature_importances_ * 100\n",
                "\n",
                "# Build DataFrame\n",
                "Importance = pd.DataFrame({'Importance': importances}, index=feature_names)\n",
                "\n",
                "# Sort and plot\n",
                "Importance.sort_values('Importance').plot(kind='barh', color='r', figsize=(8,5))\n",
                "plt.xlabel('Variable Importance (%)')\n",
                "plt.title(\"Feature Importance in Decision Tree\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2 â€“ Focus on two features for visualization\n",
                "\n",
                "For easy plotting, let's choose just two numerical features:\n",
                "- **loan_int_rate** â†’ the loan's interest rate\n",
                "- **loan_percent_income** â†’ what fraction of income goes to loan payments\n",
                "\n",
                "This creates a 2D feature space where we can plot decision regions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cols = [\"loan_int_rate\", \"loan_percent_income\"]\n",
                "\n",
                "X_train, X_val, X_test, y_train, y_val, y_test, cat_cols, num_cols, preprocess = make_data(df, cols=cols)\n",
                "\n",
                "model = model_tree(preprocess, X_train, X_val, y_train, y_val,\n",
                "                   max_depth=3, val=True)  # shallow tree for clear boundaries"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3 â€“ Decision Boundary Visualization\n",
                "\n",
                "We now plot the decision regions learned by the tree."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils import plot_decision_boundary_binary\n",
                "\n",
                "plot_decision_boundary_binary(\n",
                "    model, X_train[:1000], y_train[:1000], feature_names=cols,\n",
                "    title=\"Loan Approval Decision Boundary (max_depth=3)\"\n",
                ")\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}